{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmistroni/OpenBB_Experiments/blob/main/openbbagent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What we will attempt to  do here is to create an Agent that will call Openbb functions and big query\n",
        "### We will use Smolagents first and then we will expand little by little"
      ],
      "metadata": {
        "id": "-yLLLb5n2mdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "L53ci9PT2rXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install litellm\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "xv48572LFC38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the OpenBB Platform with all available extensions.\n",
        "# Messages indicating package version conflicts at the end of installation can be safely ignored.\n",
        "!pip install openbb-charting\n",
        "!pip install openbb-yfinance\n",
        "!pip install openbb-finviz\n",
        "!pip install openbb-fmp\n",
        "from openbb import obb\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# There is also a nightly distribution available, openbb-nightly"
      ],
      "metadata": {
        "id": "rVFU4C4AEI3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openbb import obb\n",
        "from google.colab import userdata\n",
        "obb.equity.price.historical(symbol='AAPL',provider='yfinance')\n"
      ],
      "metadata": {
        "id": "k1jernOL_9bW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install smolagents -U\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "vMS3ax-_2xfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, DuckDuckGoSearchTool, InferenceClientModel"
      ],
      "metadata": {
        "id": "vNL0kftl3gCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import requests\n",
        "!pip install google-api-python-client\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import date, datetime\n",
        "!mkdir -p data\n",
        "from apiclient.http import MediaIoBaseDownload\n",
        "!pip install fsspec\n",
        "!pip install gcsfs\n",
        "from pandas.tseries.offsets import BDay\n",
        "import numpy as np\n",
        "from datetime import datetime, date\n",
        "from pandas.tseries.offsets import BDay\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "\n",
        "print('Authenticated')"
      ],
      "metadata": {
        "id": "Ie0SpdtJEMec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "from googleapiclient.discovery import build\n",
        "from apiclient.http import MediaIoBaseDownload\n",
        "from datetime import date\n",
        "\n",
        "\n",
        "def read_from_bucket(filename, bucket_name, to_panda=True):\n",
        "  gcs_service = build('storage', 'v1')\n",
        "  # The name for the new bucket\n",
        "  holder = 'data/{}'.format(filename.split('/')[-1])\n",
        "  print('Reading {} from {}'.format(filename,bucket_name))\n",
        "  with open(holder, 'wb') as f:\n",
        "    request = gcs_service.objects().get_media(bucket=bucket_name,\n",
        "                                              object=filename)\n",
        "    media = MediaIoBaseDownload(f, request)\n",
        "\n",
        "    done = False\n",
        "    while not done:\n",
        "      # _ is a placeholder for a progress object that we ignore.\n",
        "      # (Our file is small, so we skip reporting progress.)\n",
        "      _, done = media.next_chunk()\n",
        "\n",
        "  print('Download complete')\n",
        "  if to_panda:\n",
        "    return pd.read_csv(holder)\n",
        "\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import bigquery_storage\n",
        "from google.cloud import bigquery\n",
        "from google.cloud import bigquery_storage\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "\n",
        "def get_bigquery_as_dataframe(sql_stmnt):\n",
        "  client = bigquery.Client(project='datascience-projects')\n",
        "  bqstorageclient = bigquery_storage.BigQueryReadClient()\n",
        "  query_job = client.query(sql_stmnt)\n",
        "  return query_job.result().to_dataframe()\n",
        "\n",
        "\n",
        "def get_senate_disclosures(start_date:str = '2025-01-01',\n",
        "                                       end_date:str = '2025-03-31')-> dict:\n",
        "  sql = f\"\"\"SELECT\n",
        "          DISTINCT AS_OF_DATE,\n",
        "          TICKER\n",
        "        FROM\n",
        "          `datascience-projects`.`gcp_shareloader`.`senate_disclosures`\n",
        "        WHERE\n",
        "          DISCLOSURE LIKE '%Purchase%'\n",
        "          AND AS_OF_DATE BETWEEN DATE '{start_date}'\n",
        "          AND DATE '{end_date}' /* Replace with your desired Date A and Date B */\n",
        "        ORDER BY\n",
        "          AS_OF_DATE;\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "  bqclient = bigquery.Client(project='datascience-projects')\n",
        "  dataframe = (\n",
        "    bqclient.query(sql)\n",
        "    .result()\n",
        "    .to_dataframe()\n",
        "  )\n",
        "\n",
        "  dataframe['date'] = pd.to_datetime(dataframe['date'])\n",
        "\n",
        "  # Format the timestamp to a clear date string\n",
        "  dataframe['date'] = dataframe['date'].dt.strftime('%Y-%m-%d')\n",
        "\n",
        "  # Convert the DataFrame to a JSON string\n",
        "  # The 'orient' parameter is crucial for the desired JSON structure.\n",
        "  # 'records' is a common and useful format for APIs.\n",
        "  json_data = dataframe.to_json(orient='records')\n",
        "\n",
        "  return json_data\n",
        "\n",
        "\n",
        "\n",
        "# Compare vs industry. Check metrics against every other company  until we can find industry / sector metrics\n",
        "\n",
        "#get_senate_disclosures()\n",
        "\n"
      ],
      "metadata": {
        "id": "s3YuOArxEXZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Smolagent tools"
      ],
      "metadata": {
        "id": "l_ciTVh44Tht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from smolagents import CodeAgent, tool\n",
        "#from openbb import obb\n",
        "from google.colab import userdata\n",
        "\n",
        "@tool\n",
        "def get_senate_disclosures(start_date:str, end_date:str) -> dict:\n",
        "  \"\"\"\n",
        "    Return senate disclosures between a start_date and an end_date.\n",
        "    Args:\n",
        "        start_date(str): a string representing a date in the format YYYY-MM-DD\n",
        "        end_date(str): a string representing a date in the format YYYY-MM-DD\n",
        "  \"\"\"\n",
        "  return get_senate_disclosures(start_date, end_date)\n",
        "\n",
        "\n",
        "@tool\n",
        "def get_historical_prices_for_ticker(ticker:str,\n",
        "                                     start_date:str,\n",
        "                                     end_date:str) -> dict:\n",
        "  \"\"\"\n",
        "    Return historical prices for a ticker.\n",
        "    Args:\n",
        "        ticker (str): a string representing a ticker\n",
        "        start_date(str): a string representing a date in the format YYYY-MM-DD\n",
        "        end_date(str): a string representing a date in the format YYYY-MM-DD\n",
        "  \"\"\"\n",
        "\n",
        "  return obb.equity.price.historical(symbol='AAPL', start_date=start_date,\n",
        "         end_date=end_date, provider='yfinance')\n",
        "\n",
        "@tool\n",
        "def suggest_menu(occasion: str) -> str:\n",
        "    \"\"\"\n",
        "    Suggests a menu based on the occasion.\n",
        "    Args:\n",
        "        occasion (str): The type of occasion for the party. Allowed values are:\n",
        "                        - \"casual\": Menu for casual party.\n",
        "                        - \"formal\": Menu for formal party.\n",
        "                        - \"superhero\": Menu for superhero party.\n",
        "                        - \"custom\": Custom menu.\n",
        "    \"\"\"\n",
        "    if occasion == \"casual\":\n",
        "        return \"Pizza, snacks, and drinks.\"\n",
        "    elif occasion == \"formal\":\n",
        "        return \"3-course dinner with wine and dessert.\"\n",
        "    elif occasion == \"superhero\":\n",
        "        return \"Buffet with high-energy and healthy food.\"\n",
        "    else:\n",
        "        return \"Custom menu for the butler.\"\n",
        "\n",
        "#open bb\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8WXuRze74W1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = CodeAgent(tools=[suggest_menu, get_historical_prices_for_ticker, get_senate_disclosures], model=InferenceClientModel())\n",
        "\n",
        "agent.run(\"I want you to 1. fetch all senate disclosures between 1st of March 2025 and 1st of May 2025.2. group the results by ticker , counting how many dates per ticker we have. Display results in a table\")"
      ],
      "metadata": {
        "id": "gQjDlACC4hzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mwe2eeOQB0cC"
      },
      "outputs": [],
      "source": [
        "from litellm import completion\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "def generate_response(messages: List[Dict]) -> str:\n",
        "    \"\"\"Call LLM to get response\"\"\"\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "what_to_help_with = input(\"What do you need help with?\")\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
        "    {\"role\": \"user\", \"content\": what_to_help_with}\n",
        "]\n",
        "\n",
        "response = generate_response(messages)\n",
        "print(response)"
      ]
    }
  ]
}